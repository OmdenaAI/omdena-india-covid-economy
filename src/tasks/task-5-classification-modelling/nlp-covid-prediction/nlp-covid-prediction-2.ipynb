{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d6584af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54e75544",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"covidpred-preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3706d04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 136294 entries, 0 to 136293\n",
      "Data columns (total 10 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   Unnamed: 0           136294 non-null  int64  \n",
      " 1   cough                136294 non-null  float64\n",
      " 2   fever                136294 non-null  float64\n",
      " 3   sore_throat          136294 non-null  float64\n",
      " 4   shortness_of_breath  136294 non-null  float64\n",
      " 5   head_ache            136294 non-null  float64\n",
      " 6   corona_result        136294 non-null  int64  \n",
      " 7   age_60_and_above     136294 non-null  int64  \n",
      " 8   gender               136294 non-null  int64  \n",
      " 9   test_indication      136294 non-null  int64  \n",
      "dtypes: float64(5), int64(5)\n",
      "memory usage: 10.4 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cfda885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cough</th>\n",
       "      <th>fever</th>\n",
       "      <th>sore_throat</th>\n",
       "      <th>shortness_of_breath</th>\n",
       "      <th>head_ache</th>\n",
       "      <th>corona_result</th>\n",
       "      <th>age_60_and_above</th>\n",
       "      <th>gender</th>\n",
       "      <th>test_indication</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>122808</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>122809</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>122810</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>122811</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>122812</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  cough  fever  sore_throat  shortness_of_breath  head_ache  \\\n",
       "0      122808    1.0    0.0          0.0                  0.0        0.0   \n",
       "1      122809    1.0    0.0          0.0                  0.0        0.0   \n",
       "2      122810    0.0    0.0          0.0                  0.0        0.0   \n",
       "3      122811    0.0    1.0          0.0                  0.0        0.0   \n",
       "4      122812    1.0    0.0          0.0                  0.0        0.0   \n",
       "\n",
       "   corona_result  age_60_and_above  gender  test_indication  \n",
       "0              0                 1       1                2  \n",
       "1              1                 0       0                2  \n",
       "2              0                 0       0                2  \n",
       "3              0                 0       0                0  \n",
       "4              0                 1       0                2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f16d3e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop([\"Unnamed: 0\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "451b8a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cough</th>\n",
       "      <th>fever</th>\n",
       "      <th>sore_throat</th>\n",
       "      <th>shortness_of_breath</th>\n",
       "      <th>head_ache</th>\n",
       "      <th>corona_result</th>\n",
       "      <th>age_60_and_above</th>\n",
       "      <th>gender</th>\n",
       "      <th>test_indication</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cough  fever  sore_throat  shortness_of_breath  head_ache  corona_result  \\\n",
       "0    1.0    0.0          0.0                  0.0        0.0              0   \n",
       "1    1.0    0.0          0.0                  0.0        0.0              1   \n",
       "2    0.0    0.0          0.0                  0.0        0.0              0   \n",
       "3    0.0    1.0          0.0                  0.0        0.0              0   \n",
       "4    1.0    0.0          0.0                  0.0        0.0              0   \n",
       "\n",
       "   age_60_and_above  gender  test_indication  \n",
       "0                 1       1                2  \n",
       "1                 0       0                2  \n",
       "2                 0       0                2  \n",
       "3                 0       0                0  \n",
       "4                 1       0                2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "290a062b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125668, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.corona_result == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2de17dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10626, 9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.corona_result == 1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9569ae3b",
   "metadata": {},
   "source": [
    "## Dataset is highly unbalanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08002978",
   "metadata": {},
   "source": [
    "##  Resampling the class with corona_result = 1 into 8 different datasets and training them on 8 models and then using ensemble method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5919dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data0 = data[data.corona_result == 0]\n",
    "data1 = data[data.corona_result == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dacf9805",
   "metadata": {},
   "outputs": [],
   "source": [
    "data01 = data0[:15000]\n",
    "data02 = data0[15000:30000]\n",
    "data03 = data0[30000:45000]\n",
    "data04 = data0[45000:60000]\n",
    "data05 = data0[60000:75000]\n",
    "data06 = data0[75000:90000]\n",
    "data07 = data0[90000:105000]\n",
    "data08 = data0[105000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab049714",
   "metadata": {},
   "outputs": [],
   "source": [
    "data0 = [data01, data02, data03, data04, data05, data06, data07, data08]\n",
    "dataCombined = []\n",
    "for data in data0:\n",
    "    tempFrames = [data, data1]\n",
    "    dataCombined.append(pd.concat(tempFrames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0a25734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 9)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataCombined[0][dataCombined[0].corona_result == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec05db04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10626, 9)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataCombined[0][dataCombined[0].corona_result == 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bcce3eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "for data in dataCombined:\n",
    "    y.append(data[\"corona_result\"].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9324153a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "for data in dataCombined:\n",
    "    temp = data.drop([\"corona_result\"], axis=1)\n",
    "    x.append(temp.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68f68b4",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b1e55cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ritvi\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:07:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"sub_sample\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:07:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ritvi\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:08:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"sub_sample\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:08:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ritvi\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:08:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"sub_sample\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:08:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ritvi\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:08:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"sub_sample\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:08:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ritvi\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:08:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"sub_sample\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:08:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ritvi\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:09:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"sub_sample\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:09:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ritvi\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:09:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"sub_sample\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:09:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ritvi\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:09:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"sub_sample\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:09:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "total_accuracy = []\n",
    "total_f1 = []\n",
    "total_precision = []\n",
    "total_recall = []\n",
    "for i in range(8):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x[i], y[i], test_size=0.10)\n",
    "    xgb_classifier = xgb.XGBClassifier(max_depth=7, learning_rate=0.008, objective='multi:softprob', \n",
    "                                   n_estimators=600, sub_sample=0.8, num_class=2,\n",
    "                                   booster='gbtree', n_jobs=4)\n",
    "    xgb_classifier.fit(x_train, y_train)\n",
    "    pred = xgb_classifier.predict(x_test)\n",
    "    models.append(xgb_classifier)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    total_accuracy.append(accuracy)\n",
    "    f1 = f1_score(y_test, pred, average='macro') \n",
    "    prec = precision_score(y_test, pred, average='macro') \n",
    "    rec = recall_score(y_test, pred, average='macro')\n",
    "    total_f1.append(f1)\n",
    "    total_precision.append(prec)\n",
    "    total_recall.append(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ef16aa37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total accuracy:  0.8823798114978578\n",
      "Total f1 score:  0.874545049017958\n",
      "Total precision:  0.8876164440126997\n",
      "Total recall:  0.8676595472336271\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean\n",
    "print(\"Total accuracy: \", mean(total_accuracy))\n",
    "print(\"Total f1 score: \", mean(total_f1))\n",
    "print(\"Total precision: \", mean(total_precision))\n",
    "print(\"Total recall: \", mean(total_recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9620cedb",
   "metadata": {},
   "source": [
    "## DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aba1eab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "20686381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "361/361 [==============================] - 2s 2ms/step - loss: 0.5631 - accuracy: 0.7081\n",
      "Epoch 2/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.4353 - accuracy: 0.7963\n",
      "Epoch 3/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.3867 - accuracy: 0.8335\n",
      "Epoch 4/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.3634 - accuracy: 0.8481\n",
      "Epoch 5/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.3509 - accuracy: 0.8630\n",
      "Epoch 6/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.3435 - accuracy: 0.8648\n",
      "Epoch 7/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.3395 - accuracy: 0.8670\n",
      "Epoch 8/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.3367 - accuracy: 0.8685\n",
      "Epoch 9/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.3354 - accuracy: 0.8684\n",
      "Epoch 10/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.3339 - accuracy: 0.8690\n",
      "Epoch 1/10\n",
      "361/361 [==============================] - 2s 2ms/step - loss: 0.5749 - accuracy: 0.6782\n",
      "Epoch 2/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.4659 - accuracy: 0.7856\n",
      "Epoch 3/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.4188 - accuracy: 0.8142\n",
      "Epoch 4/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.3963 - accuracy: 0.8395\n",
      "Epoch 5/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.3854 - accuracy: 0.8478\n",
      "Epoch 6/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.3794 - accuracy: 0.8498\n",
      "Epoch 7/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.3758 - accuracy: 0.8507\n",
      "Epoch 8/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.3743 - accuracy: 0.8510\n",
      "Epoch 9/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.3726 - accuracy: 0.8504\n",
      "Epoch 10/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.3718 - accuracy: 0.8507\n",
      "Epoch 1/10\n",
      "361/361 [==============================] - 2s 2ms/step - loss: 0.5970 - accuracy: 0.6794\n",
      "Epoch 2/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.4663 - accuracy: 0.7696\n",
      "Epoch 3/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.4200 - accuracy: 0.8115\n",
      "Epoch 4/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.4017 - accuracy: 0.8287\n",
      "Epoch 5/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.3924 - accuracy: 0.8415\n",
      "Epoch 6/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.3869 - accuracy: 0.8424\n",
      "Epoch 7/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.3834 - accuracy: 0.8436\n",
      "Epoch 8/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.3813 - accuracy: 0.8439\n",
      "Epoch 9/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.3799 - accuracy: 0.8442\n",
      "Epoch 10/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.3786 - accuracy: 0.8448\n",
      "Epoch 1/10\n",
      "361/361 [==============================] - 2s 2ms/step - loss: 0.5269 - accuracy: 0.7448\n",
      "Epoch 2/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.3744 - accuracy: 0.8519\n",
      "Epoch 3/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.3390 - accuracy: 0.8658\n",
      "Epoch 4/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.3170 - accuracy: 0.8760\n",
      "Epoch 5/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.3050 - accuracy: 0.8926\n",
      "Epoch 6/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.2988 - accuracy: 0.8939\n",
      "Epoch 7/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.2953 - accuracy: 0.8929\n",
      "Epoch 8/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.2933 - accuracy: 0.8934\n",
      "Epoch 9/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.2921 - accuracy: 0.8935\n",
      "Epoch 10/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.2913 - accuracy: 0.8941\n",
      "Epoch 1/10\n",
      "361/361 [==============================] - 2s 2ms/step - loss: 0.5020 - accuracy: 0.8186\n",
      "Epoch 2/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.3534 - accuracy: 0.8678\n",
      "Epoch 3/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.3207 - accuracy: 0.8791\n",
      "Epoch 4/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.3014 - accuracy: 0.8923\n",
      "Epoch 5/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.2908 - accuracy: 0.9039\n",
      "Epoch 6/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.2849 - accuracy: 0.9041\n",
      "Epoch 7/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.2822 - accuracy: 0.9038\n",
      "Epoch 8/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.2802 - accuracy: 0.9042\n",
      "Epoch 9/10\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.2783 - accuracy: 0.90 - 1s 2ms/step - loss: 0.2789 - accuracy: 0.9038\n",
      "Epoch 10/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.2786 - accuracy: 0.9044\n",
      "Epoch 1/10\n",
      "361/361 [==============================] - 2s 2ms/step - loss: 0.5040 - accuracy: 0.8045\n",
      "Epoch 2/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.3370 - accuracy: 0.8850\n",
      "Epoch 3/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.3032 - accuracy: 0.8926\n",
      "Epoch 4/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.2831 - accuracy: 0.9114\n",
      "Epoch 5/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.2729 - accuracy: 0.9169\n",
      "Epoch 6/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.2683 - accuracy: 0.9169\n",
      "Epoch 7/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.2651 - accuracy: 0.9169\n",
      "Epoch 8/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.2636 - accuracy: 0.9169\n",
      "Epoch 9/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.2624 - accuracy: 0.9167\n",
      "Epoch 10/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.2614 - accuracy: 0.9168: 0s - loss: 0.2590 - accuracy\n",
      "Epoch 1/10\n",
      "361/361 [==============================] - 2s 2ms/step - loss: 0.5341 - accuracy: 0.7293\n",
      "Epoch 2/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.3823 - accuracy: 0.8484\n",
      "Epoch 3/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.3404 - accuracy: 0.8646\n",
      "Epoch 4/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.3206 - accuracy: 0.8853: 0s - loss: 0.322\n",
      "Epoch 5/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.3121 - accuracy: 0.8940\n",
      "Epoch 6/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.3074 - accuracy: 0.8940\n",
      "Epoch 7/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.3046 - accuracy: 0.8936\n",
      "Epoch 8/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.3028 - accuracy: 0.8935\n",
      "Epoch 9/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.3014 - accuracy: 0.8933\n",
      "Epoch 10/10\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 0.3004 - accuracy: 0.8929\n",
      "Epoch 1/10\n",
      "441/441 [==============================] - 2s 2ms/step - loss: 0.5280 - accuracy: 0.7278\n",
      "Epoch 2/10\n",
      "441/441 [==============================] - 1s 2ms/step - loss: 0.3807 - accuracy: 0.8402\n",
      "Epoch 3/10\n",
      "441/441 [==============================] - 1s 2ms/step - loss: 0.3407 - accuracy: 0.8636\n",
      "Epoch 4/10\n",
      "441/441 [==============================] - 1s 2ms/step - loss: 0.3222 - accuracy: 0.8661\n",
      "Epoch 5/10\n",
      "441/441 [==============================] - 1s 2ms/step - loss: 0.3120 - accuracy: 0.8830\n",
      "Epoch 6/10\n",
      "441/441 [==============================] - 1s 2ms/step - loss: 0.3058 - accuracy: 0.8897\n",
      "Epoch 7/10\n",
      "441/441 [==============================] - 1s 2ms/step - loss: 0.3017 - accuracy: 0.8902\n",
      "Epoch 8/10\n",
      "441/441 [==============================] - 1s 2ms/step - loss: 0.2995 - accuracy: 0.8911\n",
      "Epoch 9/10\n",
      "441/441 [==============================] - 1s 2ms/step - loss: 0.2975 - accuracy: 0.8907\n",
      "Epoch 10/10\n",
      "441/441 [==============================] - 1s 2ms/step - loss: 0.2962 - accuracy: 0.8914\n"
     ]
    }
   ],
   "source": [
    "models_dnn = []\n",
    "total_accuracy = []\n",
    "total_f1 = []\n",
    "total_precision = []\n",
    "total_recall = []\n",
    "for i in range(8):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x[i], y[i], test_size=0.10)\n",
    "    y_train_dnn = np.zeros((y_train.shape[0], 2))\n",
    "    y_test_dnn = np.zeros((y_test.shape[0], 2))\n",
    "\n",
    "    for i in range(y_train.shape[0]):\n",
    "        if y_train[i] == 0:\n",
    "            y_train_dnn[i][0] = 1\n",
    "        else:\n",
    "            y_train_dnn[i][1] = 1\n",
    "    for i in range(y_test.shape[0]):\n",
    "        if y_test[i] == 0:\n",
    "            y_test_dnn[i][0] = 1\n",
    "        else:\n",
    "            y_test_dnn[i][1] = 1\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(256))\n",
    "    model.add(keras.layers.Activation('relu'))\n",
    "    model.add(keras.layers.Dense(64))\n",
    "    model.add(keras.layers.Activation('relu'))\n",
    "    model.add(keras.layers.Dense(2))\n",
    "    model.add(keras.layers.Activation('softmax'))\n",
    "    opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train_dnn, batch_size=64, epochs=10)\n",
    "    original_pred = model.predict(x_test)\n",
    "    pred = np.zeros((original_pred.shape[0]))\n",
    "    for i in range(original_pred.shape[0]):\n",
    "        if original_pred[i][0] > original_pred[i][1]:\n",
    "            pred[i] = 0\n",
    "        else:\n",
    "            pred[i] = 1\n",
    "    models_dnn.append(model)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    total_accuracy.append(accuracy)\n",
    "    f1 = f1_score(y_test, pred, average='macro') \n",
    "    prec = precision_score(y_test, pred, average='macro') \n",
    "    rec = recall_score(y_test, pred, average='macro')\n",
    "    total_f1.append(f1)\n",
    "    total_precision.append(prec)\n",
    "    total_recall.append(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8d072257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total accuracy:  0.8820638441622549\n",
      "Total f1 score:  0.8739643010034325\n",
      "Total precision:  0.8871736895641218\n",
      "Total recall:  0.8669069904393463\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean\n",
    "print(\"Total accuracy: \", mean(total_accuracy))\n",
    "print(\"Total f1 score: \", mean(total_f1))\n",
    "print(\"Total precision: \", mean(total_precision))\n",
    "print(\"Total recall: \", mean(total_recall))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
