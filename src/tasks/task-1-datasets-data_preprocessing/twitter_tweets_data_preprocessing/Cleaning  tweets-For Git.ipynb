{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean India Tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/radix/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "\n",
    "# For file processing\n",
    "import csv\n",
    "\n",
    "# For text processing\n",
    "import re\n",
    "from emoji import demojize\n",
    "from textblob import TextBlob\n",
    "import string\n",
    "from string import punctuation\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "stop = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stopwords = set(stop)\n",
    "#stopwords.update([\"corona\", \"covid\", \"india\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and process tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = 'Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "fApril = datapath + \"April2020_TweetText.csv\"\n",
    "dfApril = pd.read_csv(fApril)\n",
    "dfApril.rename(columns = {\"0\":\"text\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "fMay = datapath + \"May2020_TweetText.csv\"\n",
    "dfMay = pd.read_csv(fMay)\n",
    "dfMay.rename(columns = {\"0\":\"text\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "fJuly = datapath + \"July2020_TweetText.csv\"\n",
    "dfJuly = pd.read_csv(fJuly)\n",
    "dfJuly.rename(columns = {\"0\":\"text\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "fAug = datapath + \"August2020_TweetText.csv\"\n",
    "dfAug = pd.read_csv(fAug)\n",
    "dfAug.rename(columns = {\"0\":\"text\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "fSept = datapath + \"Sept2020_TweetText.csv\"\n",
    "dfSept = pd.read_csv(fSept)\n",
    "dfSept.rename(columns = {\"0\":\"text\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "April Tweet Text Count:  12147\n",
      "May Tweet Text Count:  26077\n",
      "July Tweet Text Count:  36750\n",
      "August Tweet Text Count:  23999\n",
      "September Tweet Text Count:  10755\n"
     ]
    }
   ],
   "source": [
    "print(\"April Tweet Text Count: \", len(dfApril))\n",
    "print(\"May Tweet Text Count: \", len(dfMay))\n",
    "print(\"July Tweet Text Count: \", len(dfJuly))\n",
    "print(\"August Tweet Text Count: \", len(dfAug))\n",
    "print(\"September Tweet Text Count: \", len(dfSept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function taken from Herumb Shandilya notebook Omdena Sentiment Analysis at\n",
    "# https://colab.research.google.com/drive/1BdYQHRwxQmCUb_Lpu6KRjtJSImKFt5Y8\n",
    "# Talk at: https://docs.google.com/presentation/d/13UFJzvYUvjbNEAxzmg7CFbu0i07mlXHxSa0lp-S1fUo/edit#slide=id.gbc883d3cd5_2_121\n",
    "\n",
    "def clean_text(text):\n",
    "    # Convert Emoji to strings\n",
    "    #text = demojize(text)\n",
    "\n",
    "    # Remove HTML Tags\n",
    "    try:\n",
    "        text = html.document_fromstring(text).text_content()\n",
    "    except:\n",
    "        pass\n",
    "          \n",
    "    # Remove Hyperlinks\n",
    "    text = re.sub('http\\S+', ' ', text)\n",
    "    \n",
    "    # Remove html character codes ( like &amp)\n",
    "    text = re.sub('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});', ' ', text)\n",
    "    \n",
    "    # Remove Hashtags\n",
    "    text = re.sub(\"#([a-zA-Z0-9_]{1,50})\", ' ', text)\n",
    "    \n",
    "    # Remove Mentions\n",
    "    text = re.sub(\"@([a-zA-Z0-9_]{1,50})\", ' ', text)\n",
    "\n",
    "    # Remove non alphabets\n",
    "    text = re.sub('[^a-zA-Z ]+', ' ', text)    \n",
    "    \n",
    "    # Remove punctuations\n",
    "    text = re.sub('[^-9A-Za-z ]', ' ' , text)\n",
    "\n",
    "    # Lowercase and split - converts to list\n",
    "    text = text.lower().split()  \n",
    "    \n",
    "    # Remove stop and short words\n",
    "    text = [word for word in text if word not in stop and len(word) > 1]\n",
    "    \n",
    "    # Stemming\n",
    "    # text = [stemmer.stem(word) for word in text]\n",
    "\n",
    "    # Join and Return\n",
    "    return ' '.join(text )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correctSpelling(text):\n",
    "    return TextBlob(text).correct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text = \"that was acccceptance\"\n",
    "#TextBlob(text).correct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct Spelling\n",
    "#texts_April.apply(correctSpelling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Text\n",
    "texts_April = dfApril['text'].apply(clean_text)\n",
    "texts_May = dfMay['text'].apply(clean_text)\n",
    "texts_July = dfJuly['text'].apply(clean_text)\n",
    "texts_Aug = dfAug['text'].apply(clean_text)\n",
    "texts_Sept = dfSept['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenating to create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of texts: 109728\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.concat([texts_April, texts_May, texts_July, texts_Aug, texts_Sept], axis=0)\n",
    "print(\"Total Number of texts:\", len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    sacrificed everything protect corona patients ...\n",
       "1    alert shall new norms laws movement stricter o...\n",
       "2    seven promises need make extra care senior cit...\n",
       "3               please move unnecessarily help prevent\n",
       "4    dear leader nation modi ji suggestion need fol...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
