{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SentimentInference.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "YMqdYJGQ_QQM"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EilvajdN0B6",
        "outputId": "a968e9d6-7703-4856-ecfd-52308bd6d426"
      },
      "source": [
        "### THIS MAY NOT BE NEEDED FOR DEPLOY SINCE FILES ARE ON GITHUB\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2F8qzLgI2l8h",
        "outputId": "3ec8a4be-8329-4c6f-8d09-6f3a27fa163c"
      },
      "source": [
        "!pip install emoji"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: emoji in /usr/local/lib/python3.7/dist-packages (1.4.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRXELvDG30bT",
        "outputId": "846e8d0d-d8e9-4c2e-8547-259daef597b5"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import pickle\n",
        "import csv\n",
        "import plotly.graph_objects as go\n",
        "import re\n",
        "from emoji import demojize\n",
        "import string\n",
        "from string import punctuation\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop = set(stopwords.words('english'))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drlMuKEk-xb4"
      },
      "source": [
        "### Loading Trained weights and vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EImlWLXbr7Pz"
      },
      "source": [
        "### CHANGE TO GITHUB REPO WHERE STREAMLIT FILES ARE \n",
        "datapath = '/content/drive/MyDrive/Omdena-India-Socio-Economy/'\n",
        "fmodel = datapath + 'LSTM_RNN_Sentiment_model.pt'\n",
        "fvocab = datapath + 'LSTM_RNN_Sentiment_vocab.pkl'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0N9TPJdcOnT3",
        "outputId": "a5e61a2b-e5c8-4b1a-96c7-fb120da7a3ce"
      },
      "source": [
        "print(fmodel)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Omdena-India-Socio-Economy/LSTM_RNN_Sentiment_model.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_giy7rfRj6NH"
      },
      "source": [
        "### Load Trained Vocabulary\n",
        "def load_vocab(fpath):\n",
        "  pickled_data = open(fpath, 'rb')\n",
        "  vocab = pickle.load(pickled_data)\n",
        "  return vocab\n",
        "\n",
        "vocab_to_int = load_vocab(fvocab)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "504P1K5G-rUO"
      },
      "source": [
        "### Sentiment Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "holA9Ca2GQYJ"
      },
      "source": [
        "### SENTIMENT MODEL \n",
        "import torch.nn as nn\n",
        "\n",
        "class SentimentRNN(nn.Module):\n",
        "    \"\"\"\n",
        "    The RNN model that will be used to perform Sentiment analysis.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
        "        \"\"\"\n",
        "        Initialize the model by setting up the layers.\n",
        "        \"\"\"\n",
        "        super(SentimentRNN, self).__init__()\n",
        "\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "        \n",
        "        # embedding and LSTM layers\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n",
        "                            dropout=drop_prob, batch_first=True)\n",
        "        \n",
        "        # dropout layer\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        \n",
        "        # linear and sigmoid layers\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "        self.sig = nn.Sigmoid()\n",
        "        \n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        \"\"\"\n",
        "        Perform a forward pass of our model on some input and hidden state.\n",
        "        \"\"\"\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        # embeddings and lstm_out\n",
        "        x = x.long()\n",
        "        embeds = self.embedding(x)\n",
        "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "    \n",
        "        # stack up lstm outputs\n",
        "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
        "        \n",
        "        # dropout and fully-connected layer\n",
        "        out = self.dropout(lstm_out)\n",
        "        out = self.fc(out)\n",
        "        # sigmoid function\n",
        "        sig_out = self.sig(out)\n",
        "        \n",
        "        # reshape to be batch_size first\n",
        "        sig_out = sig_out.view(batch_size, -1)\n",
        "        sig_out = sig_out[:, -1] # get last batch of labels\n",
        "        \n",
        "        # return last sigmoid output and hidden state\n",
        "        return sig_out, hidden\n",
        "    \n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        ''' Initializes hidden state '''\n",
        "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
        "        # initialized to zero, for hidden state and cell state of LSTM\n",
        "        weight = next(self.parameters()).data\n",
        "        \n",
        "        \n",
        "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
        "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
        "        \n",
        "        return hidden\n",
        "        "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJZ8n7sQ_CW1"
      },
      "source": [
        "### Functions to pre-process input text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftBst5ENBvV2"
      },
      "source": [
        "def clean_text(text):\n",
        "    # Convert Emoji to strings\n",
        "    #text = demojize(text)\n",
        "\n",
        "    # Remove HTML Tags\n",
        "    try:\n",
        "        text = html.document_fromstring(text).text_content()\n",
        "    except:\n",
        "        pass\n",
        "          \n",
        "    # Remove Hyperlinks\n",
        "    text = re.sub('http\\S+', ' ', text)\n",
        "    \n",
        "    # Remove html character codes ( like &amp)\n",
        "    text = re.sub('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});', ' ', text)\n",
        "    \n",
        "    # Remove Hashtags\n",
        "    text = re.sub(\"#([a-zA-Z0-9_]{1,50})\", ' ', text)\n",
        "    \n",
        "    # Remove Mentions\n",
        "    text = re.sub(\"@([a-zA-Z0-9_]{1,50})\", ' ', text)\n",
        "\n",
        "    # Remove non alphabets\n",
        "    text = re.sub('[^a-zA-Z ]+', ' ', text)    \n",
        "    \n",
        "    # Remove punctuations\n",
        "    text = re.sub('[^-9A-Za-z ]', ' ' , text)\n",
        "\n",
        "    # Lowercase and split - converts to list\n",
        "    text = text.lower().split()  \n",
        "    \n",
        "    # Remove stop and short words\n",
        "    text = [word for word in text if word not in stop and len(word) > 1]\n",
        "    \n",
        "    # Stemming\n",
        "    # text = [stemmer.stem(word) for word in text]\n",
        "\n",
        "    # Join and Return\n",
        "    return ' '.join(text )\n",
        "\n",
        "def tokenize_text(text):\n",
        "\n",
        "    # splitting by spaces\n",
        "    test_words = text.split()\n",
        "\n",
        "    # tokens\n",
        "    test_ints = []\n",
        "    test_ints.append([vocab_to_int[word] for word in test_words if vocab_to_int.get(word)])\n",
        "\n",
        "    return test_ints\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehb12su_DMYE"
      },
      "source": [
        "def pad_features(test_ints, seq_length):\n",
        "    ''' Return features of review_ints, where each review is padded with 0's \n",
        "        or truncated to the input seq_length.\n",
        "    '''\n",
        "    \n",
        "    # getting the correct rows x cols shape\n",
        "    features = np.zeros((len(test_ints), seq_length), dtype=int)\n",
        "\n",
        "    # for each review, I grab that review and \n",
        "    for i, row in enumerate(test_ints):\n",
        "      if len(row) > 0:   # If word is not in vocabulary then there will no integer representation    \n",
        "        features[i, -len(row):] = np.array(row)[:seq_length]\n",
        "    \n",
        "    return features"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JepoIIk_KrN"
      },
      "source": [
        "### Instantiating Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNxGmy2gHml9",
        "outputId": "a3e623ae-21f3-4661-f080-1fe46b68b02b"
      },
      "source": [
        "# Instantiate the model w/ hyperparams\n",
        "vocab_size = len(vocab_to_int)+1 # +1 for the 0 padding + our word tokens\n",
        "output_size = 1\n",
        "embedding_dim = 400\n",
        "hidden_dim = 256\n",
        "n_layers = 2\n",
        "\n",
        "net = SentimentRNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
        "\n",
        "print(net)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SentimentRNN(\n",
            "  (embedding): Embedding(60399, 400)\n",
            "  (lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
            "  (sig): Sigmoid()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdNdxzfn_UCU"
      },
      "source": [
        "### Load pre-trained weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqB-PN2bO26z",
        "outputId": "a9f3d5da-2fd2-4e28-f7fe-57228e219a7f"
      },
      "source": [
        "# Load Trained Model weights\n",
        "model = net.load_state_dict(torch.load(fmodel, map_location=torch.device('cpu')))\n",
        "print(model)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<All keys matched successfully>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBW1ibCoE-O5"
      },
      "source": [
        "### Call Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HN3u8qp1Mbbe"
      },
      "source": [
        "def predict(net, test_text, sequence_length=200):\n",
        "    \n",
        "    net.eval()\n",
        "    \n",
        "    # tokenize text\n",
        "    text = clean_text(test_text)\n",
        "    test_ints = tokenize_text(text)\n",
        "    \n",
        "    # pad tokenized sequence\n",
        "    seq_length=sequence_length\n",
        "    features = pad_features(test_ints, seq_length)\n",
        "    \n",
        "    # convert to tensor to pass into your model\n",
        "    feature_tensor = torch.from_numpy(features)\n",
        "    \n",
        "    batch_size = feature_tensor.size(0)\n",
        "    \n",
        "    # initialize hidden state\n",
        "    h = net.init_hidden(batch_size)\n",
        "  \n",
        "    \n",
        "    # get the output from the model\n",
        "    output, h = net(feature_tensor, h)\n",
        "    \n",
        "    # convert output probabilities to predicted class (0 or 1)\n",
        "    pred = torch.round(output.squeeze()) \n",
        "    response = int(pred.item())\n",
        "    pred_value = output.item()\n",
        "\n",
        "    #if(pred.item()==1):\n",
        "    #    response = \"Positive sentiment\"\n",
        "    #else:\n",
        "    #    response = \"Negative sentiment\"\n",
        "    \n",
        "    \n",
        "\n",
        "    return text, response, pred_value\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMqdYJGQ_QQM"
      },
      "source": [
        "## Example Input and Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7rjt9ftAjiy",
        "outputId": "86cb7847-e20c-4f45-cdda-bcdeb91dbcff"
      },
      "source": [
        "input_text = \"people happy\"\n",
        "seq_length=51 # good to use the length that was trained on\n",
        "text, response, pred_value = predict(net, input_text, seq_length)\n",
        "print(text)\n",
        "print(response)\n",
        "print('Prediction value, pre-rounding: {:.6f}'.format(pred_value))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "people happy\n",
            "1\n",
            "Prediction value, pre-rounding: 0.998327\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "souZ3MA-_aZl",
        "outputId": "d16e3d64-897a-4130-8bdc-3ffeaa1b9ce1"
      },
      "source": [
        "input_text = \"covid was devastating\"\n",
        "seq_length=51 # good to use the length that was trained on\n",
        "text, response, pred_value = predict(net, input_text, seq_length)\n",
        "print(text)\n",
        "print(response)\n",
        "print('Prediction value, pre-rounding: {:.6f}'.format(pred_value))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "covid devastating\n",
            "0\n",
            "Prediction value, pre-rounding: 0.000275\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-QENeM7UrVy"
      },
      "source": [
        "## Processing Real time tweet files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KBlz4K9b4gZ"
      },
      "source": [
        "### THIS FILE WILL CHANGE DAILY TO REFLECT REAL TIME I.E. DAILY TWEETS\n",
        "### Appropriate file needs to be used based on user date selection\n",
        "\n",
        "#fdate = datapath + \"July_31_2021.txt\"\n",
        "fdate = datapath + \"August_1_2021.txt\""
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeq_LHr0bj34"
      },
      "source": [
        "def process_file(fdate):\n",
        "  data = pd.read_csv(fdate, delimiter = \"\\t\", quoting=csv.QUOTE_NONE, header=None)\n",
        "  data.rename({0:'text'}, axis=1, inplace=True)\n",
        "  a = list(data['text'])\n",
        "  sentiment = []\n",
        "  for input_text in a:\n",
        "    if len(input_text.split(' ')) > 10:\n",
        "      text, response, pred_value = predict(net, input_text, seq_length)\n",
        "      sentiment.append(response)\n",
        "  return sentiment"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kfdkbbr8y1x9"
      },
      "source": [
        "s = process_file(fdate)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Qf6gYZcBw5C",
        "outputId": "6ae99436-752a-435b-9772-1e01d0e79824"
      },
      "source": [
        "print(\"Number of Tweets Processed\", len(s))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Tweets Processed 319\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8iPQFoS4Tww"
      },
      "source": [
        "from collections import Counter\n",
        "c = Counter(s)\n",
        "total = c.get(1) + c.get(0)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aRttb9V8L0t"
      },
      "source": [
        "x = ['Positive Sentiment', 'Negative Sentiment']\n",
        "y = [int((c.get(1)/total)*100), int((c.get(0)/total)*100)]"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlsctI8qCGdQ",
        "outputId": "dee622fb-f05f-4a6b-f063-d87555fb90e4"
      },
      "source": [
        "total"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "319"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IogPiALy8u7Q"
      },
      "source": [
        "# Specify the plots\n",
        "bar_plots = [\n",
        "             go.Bar(x=x, y=y, name='Sentiment', marker=go.bar.Marker(color='#0343df'))\n",
        "             ]\n"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoMZhNZB9qYP"
      },
      "source": [
        "layout = go.Layout(\n",
        "title=go.layout.Title(text=\"Sentiment Analysis\", x=0.5),\n",
        "yaxis_title=\"Percent Count\",\n",
        "yaxis_ticksuffix = \"%\",\n",
        "yaxis_range=[0,100],\n",
        "xaxis_tickmode=\"array\",\n",
        "xaxis_tickvals=list(range(27)),\n",
        "xaxis_ticktext=tuple(x),\n",
        "font=dict(\n",
        "        family=\"Courier New, monospace\",\n",
        "        size=24,\n",
        "        color=\"Black\"\n",
        "    )\n",
        ")"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "KgRNkncD-eCk",
        "outputId": "33730060-f641-45a1-c21d-2276a9eabe2c"
      },
      "source": [
        "# Make the multi-bar plot\n",
        "fig = go.Figure(data=bar_plots, layout=layout)\n",
        "fig.show()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"c82feb56-1a4d-49e2-b956-76710d560b64\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"c82feb56-1a4d-49e2-b956-76710d560b64\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'c82feb56-1a4d-49e2-b956-76710d560b64',\n",
              "                        [{\"marker\": {\"color\": \"#0343df\"}, \"name\": \"Sentiment\", \"type\": \"bar\", \"x\": [\"Positive Sentiment\", \"Negative Sentiment\"], \"y\": [28, 71]}],\n",
              "                        {\"font\": {\"color\": \"Black\", \"family\": \"Courier New, monospace\", \"size\": 24}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Sentiment Analysis\", \"x\": 0.5}, \"xaxis\": {\"tickmode\": \"array\", \"ticktext\": [\"Positive Sentiment\", \"Negative Sentiment\"], \"tickvals\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26]}, \"yaxis\": {\"range\": [0, 100], \"ticksuffix\": \"%\", \"title\": {\"text\": \"Percent Count\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('c82feb56-1a4d-49e2-b956-76710d560b64');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}